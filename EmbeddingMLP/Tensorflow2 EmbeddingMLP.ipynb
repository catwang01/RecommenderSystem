{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: Tensorflow2 实现 EmbeddingMLP\n",
    "tags: 小书匠,tensorflow2,embedding,keras,movielens\n",
    "grammar_cjkRuby: true\n",
    "# renderNumberedHeading: true\n",
    "---\n",
    "\n",
    "[toc!]\n",
    "\n",
    "# Tensorflow2 实现 EmbeddingMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-latest-small.zip\n",
      "   creating: ml-latest-small/\n",
      "  inflating: ml-latest-small/links.csv  \n",
      "  inflating: ml-latest-small/tags.csv  \n",
      "  inflating: ml-latest-small/ratings.csv  \n",
      "  inflating: ml-latest-small/README.txt  \n",
      "  inflating: ml-latest-small/movies.csv  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-04-01 15:37:43--  https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:443... connected.\n",
      "WARNING: cannot verify files.grouplens.org's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 978202 (955K) [application/zip]\n",
      "Saving to: ‘ml-latest-small.zip’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  5%  119K 8s\n",
      "    50K .......... .......... .......... .......... .......... 10%  238K 5s\n",
      "   100K .......... .......... .......... .......... .......... 15% 5.51M 3s\n",
      "   150K .......... .......... .......... .......... .......... 20%  230K 3s\n",
      "   200K .......... .......... .......... .......... .......... 26% 3.71M 2s\n",
      "   250K .......... .......... .......... .......... .......... 31%  258K 2s\n",
      "   300K .......... .......... .......... .......... .......... 36% 1.98M 2s\n",
      "   350K .......... .......... .......... .......... .......... 41%  244K 2s\n",
      "   400K .......... .......... .......... .......... .......... 47%  240K 2s\n",
      "   450K .......... .......... .......... .......... .......... 52%  740K 1s\n",
      "   500K .......... .......... .......... .......... .......... 57%  340K 1s\n",
      "   550K .......... .......... .......... .......... .......... 62%  606K 1s\n",
      "   600K .......... .......... .......... .......... .......... 68%  474K 1s\n",
      "   650K .......... .......... .......... .......... .......... 73%  527K 1s\n",
      "   700K .......... .......... .......... .......... .......... 78%  634K 1s\n",
      "   750K .......... .......... .......... .......... .......... 83%  328K 0s\n",
      "   800K .......... .......... .......... .......... .......... 88%  602K 0s\n",
      "   850K .......... .......... .......... .......... .......... 94%  295K 0s\n",
      "   900K .......... .......... .......... .......... .......... 99% 3.79M 0s\n",
      "   950K .....                                                 100% 71.6M=2.5s\n",
      "\n",
      "2021-04-01 15:37:47 (383 KB/s) - ‘ml-latest-small.zip’ saved [978202/978202]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "filename=ml-latest-small\n",
    "\n",
    "rm -rf ${filename}\n",
    "rm -rf ${filename}.zip\n",
    "wget https://files.grouplens.org/datasets/movielens/${filename}.zip --no-check-certificate\n",
    "unzip ${filename}.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "datapaths = {\n",
    "    \"ratings\": \"ml-latest-small/ratings.csv\",\n",
    "    \"movies\": \"ml-latest-small/movies.csv\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ratings = pd.read_csv(datapaths['ratings'])\n",
    "ratings['click'] = ratings['rating'].apply(lambda x: 1 if x > 3.5 else 0)\n",
    "ratings.drop([\"rating\"], inplace=True, axis=1)\n",
    "scaler = StandardScaler()\n",
    "ratings[['timestamp']] = scaler.fit_transform(ratings[['timestamp']]) # 时间归一化\n",
    "\n",
    "movies = pd.read_csv(datapaths['movies'])\n",
    "genres =  pd.DataFrame(list(movies['genres'].str.split('|').values))\n",
    "genres.columns = [\"genres_{}\".format(column_name) for column_name in genres.columns]\n",
    "movies = pd.concat([movies, genres], axis=1, sort=False)\n",
    "movies.drop([\"genres\", \"title\",], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(ratings, movies, on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "genre_set = set(itertools.chain(*genres.values.tolist()))\n",
    "genre_set.remove(None)\n",
    "genre_vocab = list(genre_set)\n",
    "user_vocab =  list(df['userId'].unique())\n",
    "item_vocab =  list(df['movieId'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_trainset = int(0.8 * df.shape[0])\n",
    "traindf = df[:n_trainset]\n",
    "testdf = df[n_trainset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv(\"train.csv\", index=None)\n",
    "testdf.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load sample as tf dataset\n",
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        file_path,\n",
    "        batch_size=12,\n",
    "        label_name='click',\n",
    "        na_value=\"0\",\n",
    "        num_epochs=1 # 我们在 train 中指定 epochs，因此这里是 1\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "# split as test dataset and training dataset\n",
    "train_dataset = get_dataset(\"train.csv\")\n",
    "test_dataset = get_dataset(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 10\n",
    "# all categorical features\n",
    "categorical_columns = []\n",
    "\n",
    "# genre features vocabulary\n",
    "GENRE_FEATURES = {\"genres_{}\".format(i): genre_vocab for i in range(2)}\n",
    "for feature, vocab in GENRE_FEATURES.items():\n",
    "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(key=feature, vocabulary_list=vocab)\n",
    "    emb_col = tf.feature_column.embedding_column(cat_col, EMBEDDING_DIM)\n",
    "    categorical_columns.append(emb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie id embedding feature\n",
    "movie_col = tf.feature_column.categorical_column_with_vocabulary_list(key='movieId', vocabulary_list=item_vocab)\n",
    "movie_emb_col = tf.feature_column.embedding_column(movie_col, EMBEDDING_DIM)\n",
    "categorical_columns.append(movie_emb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user id embedding feature\n",
    "user_col = tf.feature_column.categorical_column_with_vocabulary_list(key='userId', vocabulary_list=user_vocab)\n",
    "user_emb_col = tf.feature_column.embedding_column(user_col, EMBEDDING_DIM)\n",
    "categorical_columns.append(user_emb_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all numerical features\n",
    "numerical_columns = [\n",
    "    tf.feature_column.numeric_column('timestamp'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6723/6723 [==============================] - 22s 3ms/step - loss: 0.6007 - accuracy: 0.6748 - auc_2: 0.7376 - auc_3: 0.7249\n",
      "Epoch 2/5\n",
      "6723/6723 [==============================] - 14s 2ms/step - loss: 0.5468 - accuracy: 0.7210 - auc_2: 0.7954 - auc_3: 0.7879\n",
      "Epoch 3/5\n",
      "6723/6723 [==============================] - 15s 2ms/step - loss: 0.5269 - accuracy: 0.7340 - auc_2: 0.8122 - auc_3: 0.8056 0s - loss: 0.5281 - accuracy: 0.7335 -\n",
      "Epoch 4/5\n",
      "6723/6723 [==============================] - 16s 2ms/step - loss: 0.5129 - accuracy: 0.7428 - auc_2: 0.8233 - auc_3: 0.8179\n",
      "Epoch 5/5\n",
      "6723/6723 [==============================] - 15s 2ms/step - loss: 0.5009 - accuracy: 0.7493 - auc_2: 0.8324 - auc_3: 0.8275\n",
      "   1681/Unknown - 5s 3ms/step - loss: 0.6378 - accuracy: 0.6441 - auc_2: 0.6937 - auc_3: 0.5650- 5s 3ms/step - loss: 0.6376 - accuracy: 0.6442 - auc_2: 0.6939 - auc_3: 0.56\n",
      "\n",
      "Test Loss 0.6378426959938693, Test Accuracy 0.6440896391868591, Test ROC AUC 0.6937441229820251, Test PR AUC 0.5650314092636108\n",
      "Predicted good rating: 65.23%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 54.12%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 72.58%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 71.26%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 82.23%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 74.91%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 84.56%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 52.84%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 1.19%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 53.50%  | Actual rating label:  Bad Rating\n",
      "Predicted good rating: 30.00%  | Actual rating label:  Good Rating\n",
      "Predicted good rating: 5.03%  | Actual rating label:  Bad Rating\n"
     ]
    }
   ],
   "source": [
    "# embedding + MLP model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n",
    "\n",
    "# compile the model, set loss function, optimizer and evaluation metrics\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy', tf.keras.metrics.AUC(curve='ROC'), tf.keras.metrics.AUC(curve='PR')]\n",
    ")\n",
    "\n",
    "# train the model\n",
    "model.fit(train_dataset, epochs=5)\n",
    "\n",
    "# evaluate the model\n",
    "test_loss, test_accuracy, test_roc_auc, test_pr_auc = model.evaluate(test_dataset)\n",
    "print('\\n\\nTest Loss {}, Test Accuracy {}, Test ROC AUC {}, Test PR AUC {}'.format(test_loss, test_accuracy,\n",
    "                                                                                   test_roc_auc, test_pr_auc))\n",
    "\n",
    "# print some predict results\n",
    "predictions = model.predict(test_dataset)\n",
    "for prediction, goodRating in zip(predictions[:12], list(test_dataset)[0][1][:12]):\n",
    "    print(\"Predicted good rating: {:.2%}\".format(prediction[0]),\n",
    "          \" | Actual rating label: \",\n",
    "          (\"Good Rating\" if bool(goodRating) else \"Bad Rating\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "1. http://localhost:8888/lab/tree/RecommenderSystem/EmbeddingMLP/Tensorflow2%20EmbeddingMLP.ipynb\n",
    "2. https://github.com/wzhe06/SparrowRecSys/blob/90d20f84aa6184963290ee87b4766a82b1c1280e/TFRecModel/src/com/sparrowrecsys/offline/tensorflow/EmbeddingMLP.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tensorflow2': conda)",
   "language": "python",
   "name": "python361064bittensorflow2conda916f6dc8789a43e39b82205c8a731f83"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
